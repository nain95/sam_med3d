import torch
import torch.nn as nn
import torch.nn.functional as F
import medim
import medim.models.sam_med3d as model_utils
from medim.models._pretrain import check_and_download_weights_from_hf_url
import numpy as np

def overriding():
    """ê¸°ì¡´ BLIP2 ì½”ë“œì™€ ë™ì¼í•œ overriding í•¨ìˆ˜"""
    original_load_pretrained_weights = model_utils.load_pretrained_weights

    def optimized_load_pretrained_weights(model, checkpoint_path, mode="nnunet", state_dict_key=None):
        ckpt_local_path = checkpoint_path
        if checkpoint_path.startswith("https://huggingface.co"):
            ckpt_local_path = check_and_download_weights_from_hf_url(checkpoint_path)
        if mode == 'nnunet':
            load_nnunet_pretrained_weights(model, ckpt_local_path)
        elif mode == 'torch':
            with open(ckpt_local_path, "rb") as f:
                state_dict = torch.load(f, map_location='cpu', weights_only=False)
            if state_dict_key:
                state_dict = state_dict[state_dict_key]
            model.load_state_dict(state_dict)
        else:
            raise NotImplementedError(f"mode {mode} for weight loading is not implemented")

    model_utils.load_pretrained_weights = optimized_load_pretrained_weights


class DiceLoss(nn.Module):
    def __init__(self, smooth=1e-6):
        super().__init__()
        self.smooth = smooth
    
    def forward(self, pred, target):
        pred = torch.sigmoid(pred)
        pred_flat = pred.reshape(pred.size(0), -1)
        target_flat = target.reshape(target.size(0), -1)
        
        intersection = (pred_flat * target_flat).sum(dim=1)
        dice = (2. * intersection + self.smooth) / (pred_flat.sum(dim=1) + target_flat.sum(dim=1) + self.smooth)
        return 1 - dice.mean()


class IoULoss(nn.Module):
    """ê°œì„ ëœ IoU Loss - í…ì„œ ì—°ì†ì„± ë³´ì¥"""
    def __init__(self, smooth=1e-6):
        super().__init__()
        self.smooth = smooth
    
    def forward(self, pred, target):
        pred = torch.sigmoid(pred)
        # reshape() ì‚¬ìš©ìœ¼ë¡œ ì—°ì†ì„± ë¬¸ì œ í•´ê²°
        pred_flat = pred.reshape(pred.size(0), -1)
        target_flat = target.reshape(target.size(0), -1)
        
        intersection = (pred_flat * target_flat).sum(dim=1)
        union = pred_flat.sum(dim=1) + target_flat.sum(dim=1) - intersection
        iou = (intersection + self.smooth) / (union + self.smooth)
        return 1 - iou.mean()


class FocalLoss(nn.Module):
    """ê°œì„ ëœ Focal Loss"""
    def __init__(self, alpha=0.8, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, pred, target):
        bce_loss = F.binary_cross_entropy_with_logits(pred, target, reduction='none')
        p_t = torch.exp(-bce_loss)
        alpha_t = self.alpha * target + (1 - self.alpha) * (1 - target)
        focal_loss = alpha_t * (1 - p_t) ** self.gamma * bce_loss
        return focal_loss.mean()


class SAMFineTuner(nn.Module):
    """ê°œì„ ëœ SAM-Med3D Fine-tuning ëª¨ë¸ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë° ì•ˆì •ì„± í–¥ìƒ"""
    
    def __init__(self, checkpoint_path=None, representation_dim=256, freeze_encoder=False, 
                 use_gradient_checkpointing=True):
        super().__init__()
        overriding()
        
        self.representation_dim = representation_dim
        self.use_gradient_checkpointing = use_gradient_checkpointing
        
        # SAM-Med3D ë¡œë“œ (ì˜¬ë°”ë¥¸ URL)
        if checkpoint_path is None:
            ckpt_path = "https://huggingface.co/blueyo0/SAM-Med3D/resolve/main/sam_med3d_turbo.pth"
        else:
            ckpt_path = checkpoint_path
            
        print(f"ğŸ“¥ SAM-Med3D ë¡œë”© ì¤‘... ({ckpt_path})")
        try:
            self.sam = medim.create_model("SAM-Med3D", pretrained=True, checkpoint_path=ckpt_path)
            print(f"âœ… SAM-Med3D ë¡œë“œ ì™„ë£Œ")
            
            # Gradient checkpointing í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
            if self.use_gradient_checkpointing and hasattr(self.sam, 'image_encoder'):
                if hasattr(self.sam.image_encoder, 'gradient_checkpointing_enable'):
                    self.sam.image_encoder.gradient_checkpointing_enable()
                    print("ğŸ”„ Gradient checkpointing í™œì„±í™”")
                
        except Exception as e:
            print(f"âŒ SAM-Med3D ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e
        
        # Encoder freeze ì˜µì…˜
        if freeze_encoder:
            self.freeze_sam_encoder()
        
        # SAM ëª¨ë¸ì˜ ì‹¤ì œ ì¶œë ¥ ì°¨ì› í™•ì¸ì„ ìœ„í•œ ë”ë¯¸ forward
        self._initialize_repr_head(representation_dim)
        
        # Loss functions with improved stability
        self.dice_loss = DiceLoss(smooth=1e-6)
        self.iou_loss = IoULoss(smooth=1e-6)
        self.focal_loss = FocalLoss(alpha=0.8, gamma=2.0)
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•œ ì„¤ì •
        self._setup_memory_optimization()
        
        print("ğŸ§  ê°œì„ ëœ SAM Fine-tuner ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   Representation dim: {representation_dim}")
        print(f"   Gradient checkpointing: {use_gradient_checkpointing}")
        print(f"   Encoder frozen: {freeze_encoder}")
    
    def _setup_memory_optimization(self):
        """ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •"""
        # Mixed precisionì„ ìœ„í•œ ì„¤ì •
        for module in self.modules():
            if isinstance(module, (nn.Conv3d, nn.Linear)):
                # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ê°œì„ 
                if hasattr(module, 'weight') and module.weight is not None:
                    if len(module.weight.shape) > 2:  # Conv layer
                        nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
                    else:  # Linear layer
                        nn.init.xavier_normal_(module.weight)
                
                # Bias ì´ˆê¸°í™”
                if hasattr(module, 'bias') and module.bias is not None:
                    nn.init.constant_(module.bias, 0)
        
        print("ğŸ¯ ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • ì™„ë£Œ")

    def _initialize_repr_head(self, representation_dim):
        """SAM encoder ì¶œë ¥ ì°¨ì›ì— ë§ì¶° representation head ì´ˆê¸°í™” - 128Â³ ëŒ€ì‘"""
        
        # ìˆ˜ì •ëœ ë”ë¯¸ ì…ë ¥ (128Â³)
        dummy_input = torch.randn(1, 1, 128, 128, 128)
        
        print("ğŸ” SAM encoder ì¶œë ¥ ì°¨ì› í™•ì¸ ì¤‘...")
        
        with torch.no_grad():
            try:
                dummy_output = self.sam.image_encoder(dummy_input)
                sam_output_shape = dummy_output.shape
                print(f"ğŸ“ SAM image encoder ì¶œë ¥ shape: {sam_output_shape}")
                
                if len(sam_output_shape) == 5:  # [B, C, D, H, W]
                    sam_feature_dim = sam_output_shape[1]  # 256 ë˜ëŠ” ë‹¤ë¥¸ ê°’
                    
                    # Adaptive poolingìœ¼ë¡œ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬
                    self.repr_head = nn.Sequential(
                        nn.AdaptiveAvgPool3d(1),  # [B, C, D, H, W] -> [B, C, 1, 1, 1]
                        nn.Flatten(),             # [B, C, 1, 1, 1] -> [B, C]
                        nn.Linear(sam_feature_dim, representation_dim),
                        nn.LayerNorm(representation_dim),
                        nn.GELU(),  # ReLU ëŒ€ì‹  GELU ì‚¬ìš©
                        nn.Dropout(0.1),
                        nn.Linear(representation_dim, representation_dim)
                    )
                    
                    print(f"âœ… Representation head ì´ˆê¸°í™”: {sam_feature_dim} -> {representation_dim}")
                    
                elif len(sam_output_shape) == 2:  # ì´ë¯¸ [B, C] í˜•íƒœ
                    sam_feature_dim = sam_output_shape[1]
                    
                    self.repr_head = nn.Sequential(
                        nn.Linear(sam_feature_dim, representation_dim),
                        nn.LayerNorm(representation_dim),
                        nn.GELU(),
                        nn.Dropout(0.1),
                        nn.Linear(representation_dim, representation_dim)
                    )
                    
                    print(f"âœ… Representation head ì´ˆê¸°í™” (2D): {sam_feature_dim} -> {representation_dim}")
                    
                else:
                    # ì˜ˆìƒì¹˜ ëª»í•œ í˜•íƒœì˜ ê²½ìš° adaptive ì²˜ë¦¬
                    total_features = torch.prod(torch.tensor(sam_output_shape[1:]))
                    
                    self.repr_head = nn.Sequential(
                        nn.AdaptiveAvgPool3d(1) if len(sam_output_shape) == 5 else nn.Identity(),
                        nn.Flatten(),
                        nn.Linear(int(total_features), representation_dim),
                        nn.LayerNorm(representation_dim),
                        nn.GELU(),
                        nn.Dropout(0.1),
                        nn.Linear(representation_dim, representation_dim)
                    )
                    
                    print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í˜•íƒœ, adaptive ì²˜ë¦¬: {total_features} -> {representation_dim}")
                    
            except Exception as e:
                print(f"âŒ SAM ì¶œë ¥ ì°¨ì› í™•ì¸ ì‹¤íŒ¨: {e}")
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì • (ë” ìœ ì—°í•˜ê²Œ)
                self.repr_head = nn.Sequential(
                    nn.AdaptiveAvgPool3d(1),
                    nn.Flatten(),
                    nn.Linear(256, representation_dim),  # ê¸°ë³¸ê°’
                    nn.LayerNorm(representation_dim),
                    nn.GELU(),
                    nn.Dropout(0.1),
                    nn.Linear(representation_dim, representation_dim)
                )
                print(f"ğŸ”§ ê¸°ë³¸ representation head ì‚¬ìš©: 256 -> {representation_dim}")

    def forward(self, image, mask=None, return_features=False):
        """ê°œì„ ëœ Forward pass - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë° ì•ˆì •ì„± í–¥ìƒ"""
        batch_size = image.shape[0]
        device = image.device
        
        # ì…ë ¥ ê²€ì¦
        if image.dim() != 5 or image.shape[1] != 1:
            raise ValueError(f"ì…ë ¥ ì´ë¯¸ì§€ í˜•íƒœê°€ ì˜ëª»ë¨: {image.shape}, ì˜ˆìƒ: [B, 1, D, H, W]")
        
        # ì…ë ¥ í…ì„œ ì—°ì†ì„± ë³´ì¥
        if not image.is_contiguous():
            image = image.contiguous()
        
        # Image encoding with error handling and memory optimization
        try:
            if self.use_gradient_checkpointing and self.training:
                # Gradient checkpointing ì‚¬ìš©ì‹œ
                image_embeddings = torch.utils.checkpoint.checkpoint(
                    self.sam.image_encoder, image, use_reentrant=False
                )
            else:
                image_embeddings = self.sam.image_encoder(image)
                
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"âŒ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: {e}")
                print("ğŸ’¡ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ gradient_accumulation_stepsì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
            raise e
        except Exception as e:
            print(f"âŒ Image encoder ì—ëŸ¬: {e}")
            raise e
        
        # Representation features
        try:
            repr_features = self.repr_head(image_embeddings)
        except Exception as e:
            print(f"âŒ Representation head ì—ëŸ¬: {e}")
            print(f"   Image embeddings shape: {image_embeddings.shape}")
            raise e
        
        results = {
            'image_embeddings': image_embeddings,
            'representation_features': repr_features
        }
        
        # Featuresë§Œ ë¦¬í„´í•˜ëŠ” ê²½ìš° (downstream tasksìš©)
        if return_features:
            return results
        
        # Segmentation head (ë§ˆìŠ¤í¬ê°€ ìˆì„ ë•Œë§Œ)
        if mask is not None:
            # ë§ˆìŠ¤í¬ ì…ë ¥ ê²€ì¦
            if mask.shape != image.shape:
                raise ValueError(f"ë§ˆìŠ¤í¬ì™€ ì´ë¯¸ì§€ í¬ê¸° ë¶ˆì¼ì¹˜: mask {mask.shape} vs image {image.shape}")
            
            # ë§ˆìŠ¤í¬ í…ì„œ ì—°ì†ì„± ë³´ì¥
            if not mask.is_contiguous():
                mask = mask.contiguous()
                
            try:
                # Prompt encoding (no prompts)
                sparse_embeddings, dense_embeddings = self.sam.prompt_encoder(
                    points=None, boxes=None, masks=None
                )
                
                # Mask prediction with memory optimization
                if self.use_gradient_checkpointing and self.training:
                    # Gradient checkpointing for mask decoder
                    def mask_decoder_forward(img_emb, img_pe, sparse_emb, dense_emb):
                        return self.sam.mask_decoder(
                            image_embeddings=img_emb,
                            image_pe=img_pe,
                            sparse_prompt_embeddings=sparse_emb,
                            dense_prompt_embeddings=dense_emb,
                            multimask_output=False,
                        )
                    
                    low_res_masks, iou_predictions = torch.utils.checkpoint.checkpoint(
                        mask_decoder_forward,
                        image_embeddings,
                        self.sam.prompt_encoder.get_dense_pe(),
                        sparse_embeddings,
                        dense_embeddings,
                        use_reentrant=False
                    )
                else:
                    low_res_masks, iou_predictions = self.sam.mask_decoder(
                        image_embeddings=image_embeddings,
                        image_pe=self.sam.prompt_encoder.get_dense_pe(),
                        sparse_prompt_embeddings=sparse_embeddings,
                        dense_prompt_embeddings=dense_embeddings,
                        multimask_output=False,
                    )
                
                # Upsampling to original input size
                pred_masks = F.interpolate(
                    low_res_masks,
                    size=image.shape[2:],  # (128, 128, 128)
                    mode='trilinear',
                    align_corners=False
                )
                
                results.update({
                    'pred_masks': pred_masks,
                    'iou_predictions': iou_predictions,
                    'low_res_masks': low_res_masks
                })
                
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"âŒ Mask decoder GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: {e}")
                raise e
            except Exception as e:
                print(f"âŒ Mask decoder ì—ëŸ¬: {e}")
                raise e
        
        return results

    def calculate_loss(self, pred_masks, target_masks, iou_predictions=None, 
                      representation_features=None, loss_weights=None):
        """ê°œì„ ëœ Loss ê³„ì‚° - í…ì„œ ì—°ì†ì„± ë³´ì¥"""
        if loss_weights is None:
            loss_weights = {
                'dice': 3.0,
                'focal': 1.0,
                'iou': 1.0,
                'iou_pred': 0.02,
                'representation': 0.01
            }
        
        # í…ì„œ ì—°ì†ì„± ë³´ì¥
        if not pred_masks.is_contiguous():
            pred_masks = pred_masks.contiguous()
        if not target_masks.is_contiguous():
            target_masks = target_masks.contiguous()
        
        losses = {}
        
        # Segmentation losses
        dice_loss = self.dice_loss(pred_masks, target_masks)
        focal_loss = self.focal_loss(pred_masks, target_masks)
        iou_loss = self.iou_loss(pred_masks, target_masks)
        
        losses['dice_loss'] = dice_loss
        losses['focal_loss'] = focal_loss
        losses['iou_loss'] = iou_loss
        
        # IoU prediction loss
        if iou_predictions is not None:
            with torch.no_grad():
                pred_sigmoid = torch.sigmoid(pred_masks)
                # reshape() ì‚¬ìš©ìœ¼ë¡œ ì—°ì†ì„± ë¬¸ì œ í•´ê²°
                target_flat = target_masks.reshape(target_masks.shape[0], -1)
                pred_flat = pred_sigmoid.reshape(pred_sigmoid.shape[0], -1)
                
                intersection = (pred_flat * target_flat).sum(dim=1)
                union = pred_flat.sum(dim=1) + target_flat.sum(dim=1) - intersection
                true_iou = intersection / (union + 1e-6)
            
            iou_pred_loss = F.mse_loss(iou_predictions.squeeze(), true_iou)
            losses['iou_pred_loss'] = iou_pred_loss
        else:
            losses['iou_pred_loss'] = torch.tensor(0.0, device=pred_masks.device)
        
        # Representation learning loss (L2 regularization)
        if representation_features is not None:
            repr_loss = torch.mean(torch.norm(representation_features, dim=1))
            losses['representation_loss'] = repr_loss
        else:
            losses['representation_loss'] = torch.tensor(0.0, device=pred_masks.device)
        
        # Total loss
        total_loss = (
            loss_weights['dice'] * dice_loss +
            loss_weights['focal'] * focal_loss +
            loss_weights['iou'] * iou_loss +
            loss_weights['iou_pred'] * losses['iou_pred_loss'] +
            loss_weights['representation'] * losses['representation_loss']
        )
        
        losses['total_loss'] = total_loss
        
        return losses

    def extract_sam_encoder(self):
        """SAM encoder ì¶”ì¶œ (ë‹¤ë¥¸ ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´)"""
        return self.sam.image_encoder
    
    def freeze_sam_encoder(self):
        """SAM encoder freeze"""
        for param in self.sam.image_encoder.parameters():
            param.requires_grad = False
        print("ğŸ§Š SAM encoder frozen")
    
    def unfreeze_sam_encoder(self):
        """SAM encoder unfreeze"""
        for param in self.sam.image_encoder.parameters():
            param.requires_grad = True
        print("ğŸ”¥ SAM encoder unfrozen")
        
    def freeze_decoder(self):
        """SAM decoder freeze (encoderë§Œ fine-tuningí•  ë•Œ)"""
        for param in self.sam.mask_decoder.parameters():
            param.requires_grad = False
        for param in self.sam.prompt_encoder.parameters():
            param.requires_grad = False
        print("ğŸ§Š SAM decoder & prompt encoder frozen")
    
    def unfreeze_decoder(self):
        """SAM decoder unfreeze"""
        for param in self.sam.mask_decoder.parameters():
            param.requires_grad = True
        for param in self.sam.prompt_encoder.parameters():
            param.requires_grad = True
        print("ğŸ”¥ SAM decoder & prompt encoder unfrozen")

    def get_trainable_params(self):
        """í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ì •ë³´ ë°˜í™˜"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'frozen_params': total_params - trainable_params,
            'trainable_ratio': trainable_params / total_params
        }


def calculate_metrics(pred_masks, target_masks, threshold=0.5):
    """ê°œì„ ëœ segmentation metrics ê³„ì‚° - í…ì„œ ì—°ì†ì„± ë³´ì¥"""
    pred_binary = (torch.sigmoid(pred_masks) > threshold).float()
    
    # í…ì„œ ì—°ì†ì„± ë³´ì¥
    if not pred_binary.is_contiguous():
        pred_binary = pred_binary.contiguous()
    if not target_masks.is_contiguous():
        target_masks = target_masks.contiguous()
    
    # Batch-wise ê³„ì‚°
    batch_size = pred_binary.shape[0]
    metrics = {
        'dice': [],
        'iou': [],
        'accuracy': [],
        'sensitivity': [],
        'specificity': [],
        'precision': []
    }
    
    for i in range(batch_size):
        # reshape() ì‚¬ìš©ìœ¼ë¡œ ì—°ì†ì„± ë¬¸ì œ í•´ê²°
        pred_flat = pred_binary[i].reshape(-1)
        target_flat = target_masks[i].reshape(-1)
        
        # Basic metrics
        intersection = (pred_flat * target_flat).sum()
        union = pred_flat.sum() + target_flat.sum() - intersection
        
        # Dice score
        dice = (2 * intersection) / (pred_flat.sum() + target_flat.sum() + 1e-6)
        
        # IoU
        iou = intersection / (union + 1e-6)
        
        # Accuracy
        correct = (pred_flat == target_flat).sum()
        accuracy = correct / pred_flat.numel()
        
        # Confusion matrix elements
        tp = intersection  # True Positive
        fp = pred_flat.sum() - tp  # False Positive
        fn = target_flat.sum() - tp  # False Negative
        tn = ((1 - pred_flat) * (1 - target_flat)).sum()  # True Negative
        
        # Sensitivity (Recall)
        sensitivity = tp / (tp + fn + 1e-6)
        
        # Specificity
        specificity = tn / (tn + fp + 1e-6)
        
        # Precision
        precision = tp / (tp + fp + 1e-6)
        
        metrics['dice'].append(dice.item())
        metrics['iou'].append(iou.item())
        metrics['accuracy'].append(accuracy.item())
        metrics['sensitivity'].append(sensitivity.item())
        metrics['specificity'].append(specificity.item())
        metrics['precision'].append(precision.item())
    
    # í‰ê·  ê³„ì‚°
    avg_metrics = {key: np.mean(values) for key, values in metrics.items()}
    
    return avg_metrics


def test_improved_model():
    """ê°œì„ ëœ ëª¨ë¸ ì°¨ì› í…ŒìŠ¤íŠ¸ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í¬í•¨"""
    print("ğŸ§ª ê°œì„ ëœ ëª¨ë¸ ì°¨ì› í…ŒìŠ¤íŠ¸...")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"   í…ŒìŠ¤íŠ¸ ë””ë°”ì´ìŠ¤: {device}")
    
    # ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        initial_memory = torch.cuda.memory_allocated() / 1e9
        print(f"   ì´ˆê¸° GPU ë©”ëª¨ë¦¬: {initial_memory:.2f} GB")
    
    try:
        # ëª¨ë¸ ìƒì„±
        print("ğŸ¤– ëª¨ë¸ ìƒì„± ì¤‘...")
        model = SAMFineTuner(
            representation_dim=256,
            freeze_encoder=False, 
            use_gradient_checkpointing=True
        ).to(device)
        
        if torch.cuda.is_available():
            model_memory = torch.cuda.memory_allocated() / 1e9
            print(f"   ëª¨ë¸ ë¡œë“œ í›„ GPU ë©”ëª¨ë¦¬: {model_memory:.2f} GB")
        
        # íŒŒë¼ë¯¸í„° ì •ë³´
        param_info = model.get_trainable_params()
        print(f"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ì •ë³´:")
        print(f"   ì „ì²´: {param_info['total_params']:,}")
        print(f"   í•™ìŠµê°€ëŠ¥: {param_info['trainable_params']:,}")
        print(f"   ê³ ì •: {param_info['frozen_params']:,}")
        print(f"   í•™ìŠµê°€ëŠ¥ ë¹„ìœ¨: {param_info['trainable_ratio']:.1%}")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì˜¬ë°”ë¥¸ 128Â³ í¬ê¸°)
        batch_size = 1  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ë°°ì¹˜ í¬ê¸° ì¤„ì„
        image = torch.randn(batch_size, 1, 128, 128, 128, device=device)
        mask = torch.randint(0, 2, (batch_size, 1, 128, 128, 128), device=device).float()
        
        print(f"ğŸ” ì…ë ¥ í…ŒìŠ¤íŠ¸ - Image: {image.shape}, Mask: {mask.shape}")
        
        if torch.cuda.is_available():
            data_memory = torch.cuda.memory_allocated() / 1e9
            print(f"   ë°ì´í„° ë¡œë“œ í›„ GPU ë©”ëª¨ë¦¬: {data_memory:.2f} GB")
        
        # Forward pass
        print("â© Forward pass í…ŒìŠ¤íŠ¸...")
        model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        
        with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
            results = model(image, mask)
        
        print("âœ… Forward pass ì„±ê³µ!")
        for key, value in results.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {value.shape}")
        
        if torch.cuda.is_available():
            forward_memory = torch.cuda.memory_allocated() / 1e9
            print(f"   Forward í›„ GPU ë©”ëª¨ë¦¬: {forward_memory:.2f} GB")
        
        # Loss ê³„ì‚° (í›ˆë ¨ ëª¨ë“œë¡œ ì „í™˜)
        print("ğŸ’° Loss ê³„ì‚° í…ŒìŠ¤íŠ¸...")
        model.train()
        
        # ì‘ì€ ë°°ì¹˜ë¡œ Loss ê³„ì‚°
        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
            results_train = model(image, mask)
            losses = model.calculate_loss(
                results_train['pred_masks'],
                mask,
                results_train.get('iou_predictions'),
                results_train['representation_features']
            )
        
        print("âœ… Loss ê³„ì‚° ì„±ê³µ!")
        for key, value in losses.items():
            if torch.is_tensor(value):
                print(f"   {key}: {value.item():.4f}")
        
        # Metrics ê³„ì‚°
        print("ğŸ“Š Metrics ê³„ì‚° í…ŒìŠ¤íŠ¸...")
        with torch.no_grad():
            metrics = calculate_metrics(results_train['pred_masks'], mask)
        print("âœ… Metrics ê³„ì‚° ì„±ê³µ!")
        for key, value in metrics.items():
            print(f"   {key}: {value:.4f}")
        
        # Feature extraction í…ŒìŠ¤íŠ¸
        print("ğŸ” Feature extraction í…ŒìŠ¤íŠ¸...")
        model.eval()
        with torch.no_grad():
            features = model(image, return_features=True)
        print(f"   Image embeddings: {features['image_embeddings'].shape}")
        print(f"   Representation features: {features['representation_features'].shape}")
        
        # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ
        if torch.cuda.is_available():
            final_memory = torch.cuda.memory_allocated() / 1e9
            peak_memory = torch.cuda.max_memory_allocated() / 1e9
            print(f"   ìµœì¢… GPU ë©”ëª¨ë¦¬: {final_memory:.2f} GB")
            print(f"   ìµœëŒ€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {peak_memory:.2f} GB")
        
        print("\nğŸ‰ ëª¨ë“  ê°œì„ ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        
        if torch.cuda.is_available():
            error_memory = torch.cuda.memory_allocated() / 1e9
            print(f"   ì˜¤ë¥˜ ì‹œì  GPU ë©”ëª¨ë¦¬: {error_memory:.2f} GB")
        
        return False
    
    finally:
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if 'model' in locals():
            del model
        if 'image' in locals():
            del image
        if 'mask' in locals():
            del mask
        if 'results' in locals():
            del results
        if 'losses' in locals():
            del losses
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            cleaned_memory = torch.cuda.memory_allocated() / 1e9
            print(f"   ì •ë¦¬ í›„ GPU ë©”ëª¨ë¦¬: {cleaned_memory:.2f} GB")


if __name__ == "__main__":
    test_improved_model()
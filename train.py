import torch
import random
import numpy as np
import os
import sys
import time
from pathlib import Path

from config import Config
from dataloader import get_sam_med3d_dataloader
from model import SAMFineTuner
from trainer import train_model
from utils import (
    set_seed, validate_data_paths, validate_system_requirements,
    log_gpu_memory, estimate_training_time, save_training_summary,
    print_model_info
)

def print_banner():
    """ë°°ë„ˆ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ§  SAM-Med3D Fine-tuning for Brain CT ICH Segmentation")
    print("   Enhanced Version with Advanced Features")
    print("="*80)

def pre_training_checks(config):
    """í›ˆë ¨ ì „ ê²€ì‚¬"""
    print("\nğŸ” í›ˆë ¨ ì „ ì‹œìŠ¤í…œ ê²€ì‚¬...")
    
    # 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ê²€ì‚¬
    if not validate_system_requirements():
        print("âŒ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return False
    
    # 2. ë°ì´í„° ê²½ë¡œ ê²€ì‚¬
    if not validate_data_paths(config):
        print("âŒ ë°ì´í„° ê²½ë¡œ ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False
    
    # 3. ì„¤ì • ê²€ì¦
    if not config.validate_config():
        print("âŒ ì„¤ì • ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False
    
    print("âœ… ëª¨ë“  ì‚¬ì „ ê²€ì‚¬ë¥¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤.")
    return True

def main():
    """ê°œì„ ëœ ë©”ì¸ í•¨ìˆ˜"""
    # ë°°ë„ˆ ì¶œë ¥
    print_banner()
    
    try:
        # Configuration ë¡œë“œ
        print("\nâš™ï¸ ì„¤ì • ë¡œë“œ ì¤‘...")
        config = Config.from_args()
        
        # ì„¤ì • ì¶œë ¥
        print(config)
        
        # ì„¤ì • ì €ì¥
        config.save_config()
        
        # ì‹œë“œ ì„¤ì •
        set_seed(config.seed)
        
        # ì‚¬ì „ ê²€ì‚¬
        if not pre_training_checks(config):
            print("\nâŒ ì‚¬ì „ ê²€ì‚¬ ì‹¤íŒ¨. í›ˆë ¨ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return None
        
        # GPU ë©”ëª¨ë¦¬ ì´ˆê¸° ìƒíƒœ
        initial_memory = log_gpu_memory()
        
        # í›ˆë ¨ ì‹œê°„ ì¶”ì •
        print("\nâ±ï¸ í›ˆë ¨ ì‹œê°„ ì¶”ì • ì¤‘...")
        time_estimate = estimate_training_time(config)
        
        try:
            # ë°ì´í„°ë¡œë” ìƒì„±
            print(f"\nğŸ“ ë°ì´í„°ë¡œë” ìƒì„± ì¤‘...")
            
            train_loader = get_sam_med3d_dataloader(
                csv_path=config.train_csv,
                mask_dir=config.mask_dir,
                batch_size=config.batch_size, 
                is_train=True, 
                target_size=config.input_size,
                channel_method=config.channel_method,
                window_level=config.window_level,
                window_width=config.window_width,
                mask_rotation=config.mask_rotation,
                augmentation_prob=0.3 if config.batch_size >= 2 else 0.1,  # ë°°ì¹˜ í¬ê¸°ì— ë”°ë¼ ì¡°ì •
                num_workers=config.num_workers,
                verbose=True
            )
            
            val_loader = get_sam_med3d_dataloader(
                csv_path=config.val_csv,
                mask_dir=config.mask_dir,
                batch_size=config.batch_size, 
                is_train=False, 
                target_size=config.input_size,
                channel_method=config.channel_method,
                window_level=config.window_level,
                window_width=config.window_width,
                mask_rotation=config.mask_rotation,
                augmentation_prob=0.0,  # ê²€ì¦ì‹œ ì¦ê°• ì—†ìŒ
                num_workers=min(config.num_workers, 2),  # ê²€ì¦ì‹œ ì›Œì»¤ ìˆ˜ ì¤„ì„
                verbose=True
            )
            
            print(f"\nâœ… ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ")
            print(f"   í›ˆë ¨ ìƒ˜í”Œ: {len(train_loader.dataset)}")
            print(f"   ê²€ì¦ ìƒ˜í”Œ: {len(val_loader.dataset)}")
            print(f"   í›ˆë ¨ ë°°ì¹˜: {len(train_loader)}")
            print(f"   ê²€ì¦ ë°°ì¹˜: {len(val_loader)}")
            
            # ë°ì´í„° í˜•íƒœ í™•ì¸
            print(f"\nğŸ” ë°ì´í„° ìƒ˜í”Œ í™•ì¸...")
            sample_found = False
            for batch_idx, batch in enumerate(train_loader):
                if batch is not None and batch["patient_id"][0] != "dummy":
                    print(f"   âœ… ìƒ˜í”Œ ë°œê²¬ (ë°°ì¹˜ {batch_idx+1})")
                    print(f"      Image shape: {batch['image'].shape}")
                    print(f"      Mask shape: {batch['mask'].shape}")
                    print(f"      Patient ID: {batch['patient_id'][0]}")
                    print(f"      Positive ratio: {batch['positive_ratio'][0]:.3%}")
                    sample_found = True
                    break
                elif batch_idx >= 5:  # ìµœëŒ€ 5ê°œ ë°°ì¹˜ê¹Œì§€ë§Œ í™•ì¸
                    break
            
            if not sample_found:
                print("   âš ï¸ ìœ íš¨í•œ ìƒ˜í”Œì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                print("   ë°ì´í„° ê²½ë¡œì™€ ë§ˆìŠ¤í¬ ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return None
            
        except Exception as e:
            print(f"\nâŒ ë°ì´í„°ë¡œë” ìƒì„± ì‹¤íŒ¨: {e}")
            return None
        
        try:
            # ëª¨ë¸ ìƒì„±
            print(f"\nğŸ¤– ëª¨ë¸ ìƒì„± ì¤‘...")
            model = SAMFineTuner(
                checkpoint_path=None,  # SAM-Med3D-turbo ì‚¬ìš©
                representation_dim=config.visual_tokens,
                freeze_encoder=config.freeze_encoder,
                use_gradient_checkpointing=config.use_gradient_checkpointing
            )
            
            # ëª¨ë¸ ì •ë³´ ì¶œë ¥
            print_model_info(model, config)
            
            # ëª¨ë¸ ë¡œë“œ í›„ ë©”ëª¨ë¦¬ ìƒíƒœ
            model_memory = log_gpu_memory()
            
        except Exception as e:
            print(f"\nâŒ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
        
        # í›ˆë ¨ ì‹œì‘
        print(f"\nğŸš€ í›ˆë ¨ ì‹œì‘!")
        print("="*80)
        
        training_start_time = time.time()
        
        try:
            results = train_model(model, train_loader, val_loader, config)
            
            if results is None:
                print("\nâŒ í›ˆë ¨ì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return None
            
            training_end_time = time.time()
            total_training_time = training_end_time - training_start_time
            
            # í›ˆë ¨ ì™„ë£Œ
            print("\n" + "="*80)
            print("ğŸ‰ í›ˆë ¨ ì™„ë£Œ!")
            print("="*80)
            
            # ê²°ê³¼ ìš”ì•½
            summary = results.get('summary', {})
            print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼:")
            print(f"   ìµœê³  Dice: {summary.get('best_dice', 0):.4f}")
            print(f"   ìµœê³  IoU: {summary.get('best_iou', 0):.4f}")
            print(f"   ì´ í›ˆë ¨ ì‹œê°„: {total_training_time/3600:.2f}ì‹œê°„")
            print(f"   ì™„ë£Œëœ ì—í¬í¬: {summary.get('total_epochs', 0)}")
            
            # ì €ì¥ëœ íŒŒì¼ í™•ì¸
            output_files = []
            for filename in ['best_model.pth', 'sam_encoder.pth', 'latest_model.pth']:
                filepath = Path(config.output_dir) / filename
                if filepath.exists():
                    file_size = filepath.stat().st_size / (1024*1024)
                    output_files.append(f"{filename} ({file_size:.1f} MB)")
            
            if output_files:
                print(f"\nğŸ’¾ ì €ì¥ëœ íŒŒì¼:")
                for file_info in output_files:
                    print(f"   {file_info}")
            
            print(f"\nğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {config.output_dir}")
            
            # í›ˆë ¨ ìš”ì•½ ì €ì¥
            try:
                summary_file = save_training_summary(config, results)
                if summary_file:
                    print(f"ğŸ“‹ í›ˆë ¨ ìš”ì•½ ì €ì¥: {summary_file}")
            except Exception as e:
                print(f"âš ï¸ í›ˆë ¨ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            # BLIP2 í†µí•© ì•ˆë‚´
            sam_encoder_path = Path(config.output_dir) / 'sam_encoder.pth'
            if sam_encoder_path.exists():
                print(f"\nğŸ”— BLIP2 í†µí•©ìš© SAM encoder:")
                print(f"   {sam_encoder_path}")
                print(f"   ì´ íŒŒì¼ì„ BLIP2 ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ì„¸ìš”.")
            
            # WandB ë§í¬
            if config.use_wandb:
                print(f"\nğŸ“ˆ ìƒì„¸ ê²°ê³¼ëŠ” WandBì—ì„œ í™•ì¸í•˜ì„¸ìš”!")
            
            return results
            
        except Exception as e:
            print(f"\nâŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None
        
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None
        
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None
        
    finally:
        # ì •ë¦¬ ì‘ì—…
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        print(f"\nğŸ§¹ ì •ë¦¬ ì™„ë£Œ")


def quick_test():
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ"""
    print("ğŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    
    # ì„ì‹œ ì„¤ì •
    class TestConfig:
        def __init__(self):
            self.seed = 42
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.input_size = (128, 128, 128)
            self.visual_tokens = 256
            self.freeze_encoder = False
            self.use_gradient_checkpointing = True
    
    config = TestConfig()
    
    # ì‹œë“œ ì„¤ì •
    set_seed(config.seed)
    
    # ì‹œìŠ¤í…œ ê²€ì‚¬
    if not validate_system_requirements():
        return False
    
    # ëª¨ë¸ í…ŒìŠ¤íŠ¸
    try:
        print("ğŸ¤– ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")
        model = SAMFineTuner(
            representation_dim=config.visual_tokens,
            freeze_encoder=config.freeze_encoder,
            use_gradient_checkpointing=config.use_gradient_checkpointing
        )
        
        print_model_info(model, config)
        
        # ê°„ë‹¨í•œ forward í…ŒìŠ¤íŠ¸
        device = torch.device(config.device)
        model = model.to(device)
        
        dummy_input = torch.randn(1, 1, 128, 128, 128).to(device)
        dummy_mask = torch.randint(0, 2, (1, 1, 128, 128, 128)).float().to(device)
        
        model.eval()
        with torch.no_grad():
            results = model(dummy_input, dummy_mask)
        
        print("âœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        for key, value in results.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {value.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        success = quick_test()
        sys.exit(0 if success else 1)
    else:
        # ì¼ë°˜ í›ˆë ¨ ëª¨ë“œ
        result = main()
        sys.exit(0 if result is not None else 1)
import torch
import torch.nn.functional as F
from tqdm import tqdm
import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib.colors import ListedColormap
import wandb

def calculate_dice(pred, target):
    """Dice score ê³„ì‚° - ì•ˆì „í•œ reshape ì‚¬ìš©"""
    pred = torch.sigmoid(pred)
    pred_flat = pred.reshape(-1)
    target_flat = target.reshape(-1)
    
    intersection = (pred_flat * target_flat).sum()
    dice = (2. * intersection + 1e-6) / (pred_flat.sum() + target_flat.sum() + 1e-6)
    return dice.item()

def calculate_iou(pred, target):
    """IoU score ê³„ì‚° - ì•ˆì „í•œ reshape ì‚¬ìš©"""
    pred = torch.sigmoid(pred)
    pred_flat = pred.reshape(-1)
    target_flat = target.reshape(-1)
    
    intersection = (pred_flat * target_flat).sum()
    union = pred_flat.sum() + target_flat.sum() - intersection
    iou = (intersection + 1e-6) / (union + 1e-6)
    return iou.item()

def safe_tensor_operations(pred_masks, target_masks):
    """í…ì„œ ì—°ì‚°ì„ ìœ„í•œ ì•ˆì „í•œ ì „ì²˜ë¦¬"""
    if not pred_masks.is_contiguous():
        pred_masks = pred_masks.contiguous()
    if not target_masks.is_contiguous():
        target_masks = target_masks.contiguous()
    
    return pred_masks, target_masks

def create_segmentation_visualization(image, target_mask, pred_mask, patient_id, slice_idx=None):
    """ë¶„í•  ê²°ê³¼ ì‹œê°í™” ìƒì„±"""
    # ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
    if isinstance(image, torch.Tensor):
        image = image.detach().cpu().numpy()
    if isinstance(target_mask, torch.Tensor):
        target_mask = target_mask.detach().cpu().numpy()
    if isinstance(pred_mask, torch.Tensor):
        pred_mask = torch.sigmoid(pred_mask).detach().cpu().numpy()
    
    # 3D ë°ì´í„°ì—ì„œ ì¤‘ì‹¬ ìŠ¬ë¼ì´ìŠ¤ ì„ íƒ
    if len(image.shape) == 4:  # (C, D, H, W)
        image = image[0]  # ì²« ë²ˆì§¸ ì±„ë„
        target_mask = target_mask[0]
        pred_mask = pred_mask[0]
    
    if slice_idx is None:
        slice_idx = image.shape[0] // 2  # ì¤‘ì‹¬ ìŠ¬ë¼ì´ìŠ¤
    
    img_slice = image[slice_idx]
    target_slice = target_mask[slice_idx]
    pred_slice = pred_mask[slice_idx]
    
    # ì˜ˆì¸¡ì„ ì´ì§„í™”
    pred_binary = (pred_slice > 0.5).astype(np.float32)
    
    # ì‹œê°í™” ìƒì„±
    fig, axes = plt.subplots(1, 4, figsize=(16, 4))
    
    # 1. ì›ë³¸ ì´ë¯¸ì§€
    axes[0].imshow(img_slice, cmap='gray', aspect='equal')
    axes[0].set_title(f'Original\n{patient_id}')
    axes[0].axis('off')
    
    # 2. Ground Truth
    axes[1].imshow(img_slice, cmap='gray', aspect='equal')
    if target_slice.max() > 0:
        axes[1].imshow(target_slice, cmap='Reds', alpha=0.6, aspect='equal')
        axes[1].contour(target_slice, levels=[0.5], colors='red', linewidths=2)
    axes[1].set_title(f'Ground Truth\n({target_slice.sum():.0f} pixels)')
    axes[1].axis('off')
    
    # 3. Prediction
    axes[2].imshow(img_slice, cmap='gray', aspect='equal')
    if pred_binary.max() > 0:
        axes[2].imshow(pred_binary, cmap='Blues', alpha=0.6, aspect='equal')
        axes[2].contour(pred_binary, levels=[0.5], colors='blue', linewidths=2)
    axes[2].set_title(f'Prediction\n({pred_binary.sum():.0f} pixels)')
    axes[2].axis('off')
    
    # 4. Overlay Comparison
    axes[3].imshow(img_slice, cmap='gray', aspect='equal')
    if target_slice.max() > 0:
        axes[3].contour(target_slice, levels=[0.5], colors='red', linewidths=2, label='GT')
    if pred_binary.max() > 0:
        axes[3].contour(pred_binary, levels=[0.5], colors='blue', linewidths=2, label='Pred')
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    dice = calculate_dice(torch.tensor(pred_slice), torch.tensor(target_slice))
    iou = calculate_iou(torch.tensor(pred_slice), torch.tensor(target_slice))
    
    axes[3].set_title(f'Comparison\nDice: {dice:.3f}, IoU: {iou:.3f}')
    axes[3].axis('off')
    
    # ë²”ë¡€ ì¶”ê°€
    red_patch = mpatches.Patch(color='red', label='Ground Truth')
    blue_patch = mpatches.Patch(color='blue', label='Prediction')
    axes[3].legend(handles=[red_patch, blue_patch], loc='upper right')
    
    plt.tight_layout()
    return fig

def log_sample_predictions(model, dataloader, device, config, epoch, phase="val"):
    """ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ WandBì— ë¡œê¹…"""
    if not config.use_wandb or not config.log_images:
        return
    
    model.eval()
    logged_samples = 0
    max_samples = 3  # ë¡œê¹…í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(dataloader):
            if batch is None or batch["patient_id"][0] == "dummy":
                continue
            
            if logged_samples >= max_samples:
                break
            
            try:
                image = batch["image"].to(device)
                mask = batch["mask"].to(device)
                patient_id = batch["patient_id"][0]
                
                # í…ì„œ ì—°ì†ì„± ë³´ì¥
                image = image.contiguous()
                mask = mask.contiguous()
                
                # ì˜ˆì¸¡
                results = model(image, mask)
                pred_masks = results['pred_masks']
                
                # ì²« ë²ˆì§¸ ìƒ˜í”Œë§Œ ì‹œê°í™”
                img_sample = image[0]  # (1, D, H, W)
                mask_sample = mask[0]  # (1, D, H, W)
                pred_sample = pred_masks[0]  # (1, D, H, W)
                
                # ì‹œê°í™” ìƒì„±
                fig = create_segmentation_visualization(
                    img_sample, mask_sample, pred_sample, patient_id
                )
                
                # WandBì— ë¡œê¹…
                wandb.log({
                    f"{phase}_predictions/sample_{logged_samples+1}": wandb.Image(
                        fig, 
                        caption=f"Epoch {epoch} - {patient_id}"
                    )
                }, step=epoch)
                
                plt.close(fig)
                logged_samples += 1
                
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œê¹… ì‹¤íŒ¨: {e}")
                continue

def log_metrics_to_wandb(metrics_dict, epoch, phase="train"):
    """ë©”íŠ¸ë¦­ì„ WandBì— ë¡œê¹…"""
    if wandb.run is None:
        return
    
    log_dict = {}
    for key, value in metrics_dict.items():
        log_dict[f"{phase}_{key}"] = value
    
    wandb.log(log_dict, step=epoch)

def save_model_to_wandb(model, checkpoint_path, epoch, best_dice, best_iou, config):
    """ëª¨ë¸ì„ WandB artifactë¡œ ì €ì¥"""
    if not config.use_wandb:
        return
    
    try:
        # Artifact ìƒì„±
        artifact = wandb.Artifact(
            name=f"sam_med3d_epoch_{epoch}",
            type="model",
            description=f"SAM-Med3D checkpoint at epoch {epoch}",
            metadata={
                "epoch": epoch,
                "best_dice": best_dice,
                "best_iou": best_iou,
                "architecture": "SAM-Med3D",
                "task": "Brain CT ICH Segmentation"
            }
        )
        
        # íŒŒì¼ ì¶”ê°€
        artifact.add_file(checkpoint_path)
        
        # Artifact ë¡œê·¸
        wandb.log_artifact(artifact)
        print(f"ğŸ“¦ ëª¨ë¸ artifact ì €ì¥ ì™„ë£Œ: sam_med3d_epoch_{epoch}")
        
    except Exception as e:
        print(f"âš ï¸ WandB artifact ì €ì¥ ì‹¤íŒ¨: {e}")

def train_epoch(model, dataloader, optimizer, device, config):
    """í›ˆë ¨ ì—í¬í¬ - WandB ë¡œê¹… í¬í•¨"""
    model.train()
    total_loss = 0
    total_dice = 0
    total_iou = 0
    processed_batches = 0
    
    # Loss ì»´í¬ë„ŒíŠ¸ë³„ ì¶”ì 
    loss_components = {
        'dice_loss': 0,
        'focal_loss': 0,
        'iou_loss': 0,
        'iou_pred_loss': 0,
        'representation_loss': 0
    }
    
    pbar = tqdm(dataloader, desc="Training")
    
    for batch_idx, batch in enumerate(pbar):
        if batch is None:
            continue
            
        try:
            if batch["patient_id"][0] == "dummy":
                continue
            
            image = batch["image"].to(device)
            mask = batch["mask"].to(device)
            
            # í…ì„œ ì—°ì†ì„± ë³´ì¥
            image = image.contiguous()
            mask = mask.contiguous()
            
            if image.shape[0] == 0 or mask.shape[0] == 0:
                continue
            
            optimizer.zero_grad()
            
            # Forward pass
            results = model(image, mask)
            pred_masks = results['pred_masks']
            if not pred_masks.is_contiguous():
                pred_masks = pred_masks.contiguous()
            
            # Loss ê³„ì‚°
            loss_weights = {
                'dice': config.dice_weight,
                'focal': config.focal_weight,
                'iou': config.iou_weight,
                'iou_pred': config.iou_pred_weight,
                'representation': config.repr_weight
            }
            
            losses = model.calculate_loss(
                pred_masks, 
                mask,
                results.get('iou_predictions'),
                results.get('representation_features'),
                loss_weights=loss_weights
            )
            
            # Backward pass
            losses['total_loss'].backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            # Metrics ê³„ì‚°
            pred_masks, mask = safe_tensor_operations(pred_masks, mask)
            dice = calculate_dice(pred_masks, mask)
            iou = calculate_iou(pred_masks, mask)
            
            # ëˆ„ì 
            total_loss += losses['total_loss'].item()
            total_dice += dice
            total_iou += iou
            processed_batches += 1
            
            # Loss ì»´í¬ë„ŒíŠ¸ ëˆ„ì 
            for key in loss_components:
                if key in losses:
                    loss_components[key] += losses[key].item()
            
            # Progress bar ì—…ë°ì´íŠ¸
            pbar.set_postfix({
                'Loss': f'{total_loss / processed_batches:.3f}',
                'Dice': f'{total_dice / processed_batches:.3f}',
                'IoU': f'{total_iou / processed_batches:.3f}',
                'LR': f'{optimizer.param_groups[0]["lr"]:.2e}'
            })
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ {batch_idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue
    
    if processed_batches == 0:
        print("âš ï¸ ì²˜ë¦¬ëœ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return 0.0, 0.0, 0.0, {}
    
    # í‰ê·  ê³„ì‚°
    avg_loss = total_loss / processed_batches
    avg_dice = total_dice / processed_batches
    avg_iou = total_iou / processed_batches
    
    # Loss ì»´í¬ë„ŒíŠ¸ í‰ê· 
    avg_loss_components = {
        key: value / processed_batches 
        for key, value in loss_components.items()
    }
    
    return avg_loss, avg_dice, avg_iou, avg_loss_components

def validate(model, dataloader, device, config):
    """ê²€ì¦ - WandB ë¡œê¹… í¬í•¨"""
    model.eval()
    total_loss = 0
    total_dice = 0
    total_iou = 0
    processed_batches = 0
    
    # Loss ì»´í¬ë„ŒíŠ¸ë³„ ì¶”ì 
    loss_components = {
        'dice_loss': 0,
        'focal_loss': 0,
        'iou_loss': 0,
        'iou_pred_loss': 0,
        'representation_loss': 0
    }
    
    with torch.no_grad():
        pbar = tqdm(dataloader, desc="Validation")
        
        for batch_idx, batch in enumerate(pbar):
            if batch is None:
                continue
                
            try:
                if batch["patient_id"][0] == "dummy":
                    continue
                
                image = batch["image"].to(device)
                mask = batch["mask"].to(device)
                
                # í…ì„œ ì—°ì†ì„± ë³´ì¥
                image = image.contiguous()
                mask = mask.contiguous()
                
                if image.shape[0] == 0 or mask.shape[0] == 0:
                    continue
                
                # Forward pass
                results = model(image, mask)
                pred_masks = results['pred_masks']
                if not pred_masks.is_contiguous():
                    pred_masks = pred_masks.contiguous()
                
                # Loss ê³„ì‚°
                loss_weights = {
                    'dice': config.dice_weight,
                    'focal': config.focal_weight,
                    'iou': config.iou_weight,
                    'iou_pred': config.iou_pred_weight,
                    'representation': config.repr_weight
                }
                
                losses = model.calculate_loss(
                    pred_masks,
                    mask,
                    results.get('iou_predictions'),
                    results.get('representation_features'),
                    loss_weights=loss_weights
                )
                
                # Metrics ê³„ì‚°
                pred_masks, mask = safe_tensor_operations(pred_masks, mask)
                dice = calculate_dice(pred_masks, mask)
                iou = calculate_iou(pred_masks, mask)
                
                # ëˆ„ì 
                total_loss += losses['total_loss'].item()
                total_dice += dice
                total_iou += iou
                processed_batches += 1
                
                # Loss ì»´í¬ë„ŒíŠ¸ ëˆ„ì 
                for key in loss_components:
                    if key in losses:
                        loss_components[key] += losses[key].item()
                
                pbar.set_postfix({
                    'Loss': f'{total_loss / processed_batches:.3f}',
                    'Dice': f'{total_dice / processed_batches:.3f}',
                    'IoU': f'{total_iou / processed_batches:.3f}'
                })
                
            except Exception as e:
                print(f"âŒ ê²€ì¦ ë°°ì¹˜ {batch_idx} ì‹¤íŒ¨: {e}")
                continue
    
    if processed_batches == 0:
        print("âš ï¸ ê²€ì¦ì—ì„œ ì²˜ë¦¬ëœ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return 0.0, 0.0, 0.0, {}
    
    # í‰ê·  ê³„ì‚°
    avg_loss = total_loss / processed_batches
    avg_dice = total_dice / processed_batches
    avg_iou = total_iou / processed_batches
    
    # Loss ì»´í¬ë„ŒíŠ¸ í‰ê· 
    avg_loss_components = {
        key: value / processed_batches 
        for key, value in loss_components.items()
    }
    
    return avg_loss, avg_dice, avg_iou, avg_loss_components

def train_model(model, train_loader, val_loader, config):
    """ë©”ì¸ í›ˆë ¨ í•¨ìˆ˜ - WandB ë¡œê¹… í¬í•¨"""
    device = torch.device(config.device)
    model = model.to(device)
    
    # WandB ì´ˆê¸°í™”
    wandb_run = None
    if config.use_wandb:
        wandb_run = config.init_wandb()
        
        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¡œê¹…
        wandb.watch(model, log_freq=100, log_graph=True)
    
    # Optimizer ë° Scheduler
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=config.learning_rate,
        weight_decay=getattr(config, 'weight_decay', 1e-4)
    )
    
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='max', 
        factor=0.5,
        patience=3, 
    )
    
    # í›ˆë ¨ ìƒíƒœ ë³€ìˆ˜
    best_dice = 0
    best_iou = 0
    patience_counter = 0
    
    # ê²°ê³¼ ì €ì¥ìš©
    train_history = {'loss': [], 'dice': [], 'iou': []}
    val_history = {'loss': [], 'dice': [], 'iou': []}
    
    print(f"ğŸš€ í›ˆë ¨ ì‹œì‘")
    print(f"   Device: {device}")
    print(f"   Epochs: {config.epochs}")
    print(f"   Batch size: {config.batch_size}")
    print(f"   Learning rate: {config.learning_rate}")
    print(f"   Output dir: {config.output_dir}")
    if config.use_wandb:
        print(f"   WandB: {wandb.run.url}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(config.output_dir, exist_ok=True)
    
    for epoch in range(config.epochs):
        print(f"\nğŸ“Š Epoch {epoch+1}/{config.epochs}")
        print("-" * 50)
        
        # í›ˆë ¨
        train_loss, train_dice, train_iou, train_loss_components = train_epoch(
            model, train_loader, optimizer, device, config
        )
        
        # ê²€ì¦
        val_loss, val_dice, val_iou, val_loss_components = validate(
            model, val_loader, device, config
        )
        
        # Scheduler ì—…ë°ì´íŠ¸
        scheduler.step(val_dice)
        current_lr = optimizer.param_groups[0]['lr']
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        train_history['loss'].append(train_loss)
        train_history['dice'].append(train_dice)
        train_history['iou'].append(train_iou)
        
        val_history['loss'].append(val_loss)
        val_history['dice'].append(val_dice)
        val_history['iou'].append(val_iou)
        
        # WandB ë¡œê¹…
        if config.use_wandb:
            # ê¸°ë³¸ ë©”íŠ¸ë¦­ ë¡œê¹…
            metrics_dict = {
                'loss': train_loss,
                'dice': train_dice,
                'iou': train_iou,
                'learning_rate': current_lr,
                **{f"loss_{k}": v for k, v in train_loss_components.items()}
            }
            log_metrics_to_wandb(metrics_dict, epoch, "train")
            
            val_metrics_dict = {
                'loss': val_loss,
                'dice': val_dice,
                'iou': val_iou,
                **{f"loss_{k}": v for k, v in val_loss_components.items()}
            }
            log_metrics_to_wandb(val_metrics_dict, epoch, "val")
            
            # ì¶”ê°€ ë©”íŠ¸ë¦­
            wandb.log({
                'epoch': epoch,
                'patience_counter': patience_counter,
                'best_dice': best_dice,
                'best_iou': best_iou
            }, step=epoch)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"Train - Loss: {train_loss:.4f}, Dice: {train_dice:.4f}, IoU: {train_iou:.4f}")
        print(f"Val   - Loss: {val_loss:.4f}, Dice: {val_dice:.4f}, IoU: {val_iou:.4f}")
        print(f"LR    - {current_lr:.2e}")
        
        # ì´ë¯¸ì§€ ë¡œê¹… (ì£¼ê¸°ì ìœ¼ë¡œ)
        if config.use_wandb and config.log_images and (epoch + 1) % config.log_freq == 0:
            log_sample_predictions(model, val_loader, device, config, epoch, "val")
        
        # ëª¨ë¸ ì €ì¥ ì¡°ê±´
        is_best_dice = val_dice > best_dice
        is_best_iou = val_iou > best_iou
        
        if is_best_dice or is_best_iou:
            if is_best_dice:
                best_dice = val_dice
                print(f"ğŸ¯ ìƒˆë¡œìš´ ìµœê³  Dice: {best_dice:.4f}")
            
            if is_best_iou:
                best_iou = val_iou
                print(f"ğŸ¯ ìƒˆë¡œìš´ ìµœê³  IoU: {best_iou:.4f}")
            
            patience_counter = 0
            
            # ìµœê³  ëª¨ë¸ ì €ì¥
            checkpoint = {
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'epoch': epoch,
                'best_dice': best_dice,
                'best_iou': best_iou,
                'train_history': train_history,
                'val_history': val_history,
                'config': config.to_dict()
            }
            
            checkpoint_path = os.path.join(config.output_dir, 'best_model.pth')
            torch.save(checkpoint, checkpoint_path)
            
            # WandBì— ëª¨ë¸ ì €ì¥ (ì£¼ê¸°ì ìœ¼ë¡œ)
            if config.use_wandb and (epoch + 1) % config.save_model_freq == 0:
                save_model_to_wandb(model, checkpoint_path, epoch, best_dice, best_iou, config)
            
            # SAM encoderë§Œ ë³„ë„ ì €ì¥
            try:
                sam_encoder_state = {
                    'image_encoder': model.sam.image_encoder.state_dict(),
                    'dice_score': best_dice,
                    'iou_score': best_iou,
                    'config': config.to_dict()
                }
                torch.save(sam_encoder_state, os.path.join(config.output_dir, 'sam_encoder.pth'))
            except Exception as e:
                print(f"âš ï¸ SAM encoder ì €ì¥ ì‹¤íŒ¨: {e}")
            
        else:
            patience_counter += 1
            print(f"â³ Patience: {patience_counter}/{config.patience}")
        
        # Early stopping
        if patience_counter >= config.patience:
            print(f"ğŸ›‘ Early stopping at epoch {epoch+1}")
            break
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache()
    
    # í›ˆë ¨ ì™„ë£Œ
    print(f"\nğŸ‰ í›ˆë ¨ ì™„ë£Œ!")
    print(f"   ìµœê³  Dice: {best_dice:.4f}")
    print(f"   ìµœê³  IoU: {best_iou:.4f}")
    print(f"   ì €ì¥ ìœ„ì¹˜: {config.output_dir}")
    
    # ìµœì¢… ëª¨ë¸ì„ WandB artifactë¡œ ì €ì¥
    if config.use_wandb:
        final_checkpoint_path = os.path.join(config.output_dir, 'best_model.pth')
        save_model_to_wandb(model, final_checkpoint_path, "final", best_dice, best_iou, config)
        
        # WandB ì¢…ë£Œ
        wandb.finish()
    
    return model

def load_sam_encoder(checkpoint_path, model_class=None):
    """Fine-tuned SAM encoder ë¡œë“œ"""
    try:
        if checkpoint_path.endswith('sam_encoder.pth'):
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            print(f"âœ… SAM encoder ë¡œë“œ ì™„ë£Œ")
            print(f"   Dice: {checkpoint.get('dice_score', 'N/A'):.4f}")
            print(f"   IoU: {checkpoint.get('iou_score', 'N/A'):.4f}")
            return checkpoint
        else:
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            if model_class is not None:
                model = model_class()
                model.load_state_dict(checkpoint['model_state_dict'])
                return model.sam.image_encoder
            else:
                return checkpoint
                
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def resume_training(model, checkpoint_path, train_loader, val_loader, config):
    """í›ˆë ¨ ì¬ê°œ"""
    print(f"ğŸ”„ í›ˆë ¨ ì¬ê°œ: {checkpoint_path}")
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # ëª¨ë¸ ìƒíƒœ ë¡œë“œ
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # Optimizer ì¬ì„¤ì •
    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
    # íˆìŠ¤í† ë¦¬ ë¡œë“œ
    train_history = checkpoint.get('train_history', {'loss': [], 'dice': [], 'iou': []})
    val_history = checkpoint.get('val_history', {'loss': [], 'dice': [], 'iou': []})
    
    start_epoch = checkpoint['epoch'] + 1
    best_dice = checkpoint['best_dice']
    
    print(f"   ì‹œì‘ ì—í¬í¬: {start_epoch}")
    print(f"   ìµœê³  Dice: {best_dice:.4f}")
    
    # ì„¤ì • ì—…ë°ì´íŠ¸
    config.start_epoch = start_epoch
    
    return train_model(model, train_loader, val_loader, config)
"""
Í∞úÏÑ†Îêú ÌõàÎ†® Ìï®ÏàòÎì§
- Mixed precision training
- Gradient accumulation
- Î©îÎ™®Î¶¨ Ìö®Ïú®Ï†Å Ï≤òÎ¶¨
"""

import torch
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler
from tqdm import tqdm
import time
import numpy as np
from trainer_improved import (
    calculate_dice_safe, calculate_iou_safe, safe_tensor_operations,
    log_sample_predictions, log_metrics_to_wandb, get_memory_info, cleanup_memory
)


def train_epoch_improved(model, dataloader, optimizer, scaler, device, config, epoch):
    """Í∞úÏÑ†Îêú ÌõàÎ†® ÏóêÌè¨ÌÅ¨ - Mixed precision Î∞è Gradient accumulation ÏßÄÏõê"""
    model.train()
    
    total_loss = 0
    total_dice = 0
    total_iou = 0
    processed_batches = 0
    accumulated_batches = 0
    
    # Loss Ïª¥Ìè¨ÎÑåÌä∏Î≥Ñ Ï∂îÏ†Å
    loss_components = {
        'dice_loss': 0,
        'focal_loss': 0,
        'iou_loss': 0,
        'iou_pred_loss': 0,
        'representation_loss': 0
    }
    
    pbar = tqdm(dataloader, desc=f"Training Epoch {epoch+1}")
    start_time = time.time()
    
    # Gradient accumulationÏùÑ ÏúÑÌïú Ï¥àÍ∏∞Ìôî
    optimizer.zero_grad()
    
    for batch_idx, batch in enumerate(pbar):
        if batch is None or batch["patient_id"][0] == "dummy":
            continue
            
        try:
            image = batch["image"].to(device, non_blocking=True)
            mask = batch["mask"].to(device, non_blocking=True)
            
            # ÌÖêÏÑú Ïó∞ÏÜçÏÑ± Î≥¥Ïû•
            image = image.contiguous()
            mask = mask.contiguous()
            
            if image.shape[0] == 0 or mask.shape[0] == 0:
                continue
            
            # Mixed precision forward pass
            with autocast(enabled=config.use_mixed_precision):
                # Forward pass
                results = model(image, mask)
                pred_masks = results['pred_masks']
                
                if not pred_masks.is_contiguous():
                    pred_masks = pred_masks.contiguous()
                
                # Loss Í≥ÑÏÇ∞
                loss_weights = {
                    'dice': config.dice_weight,
                    'focal': config.focal_weight,
                    'iou': config.iou_weight,
                    'iou_pred': config.iou_pred_weight,
                    'representation': config.repr_weight
                }
                
                losses = model.calculate_loss(
                    pred_masks, 
                    mask,
                    results.get('iou_predictions'),
                    results.get('representation_features'),
                    loss_weights=loss_weights
                )
                
                # Gradient accumulationÏùÑ ÏúÑÌïú loss scaling
                total_loss_batch = losses['total_loss'] / config.gradient_accumulation_steps
            
            # Backward pass with mixed precision
            if config.use_mixed_precision:
                scaler.scale(total_loss_batch).backward()
            else:
                total_loss_batch.backward()
            
            accumulated_batches += 1
            
            # Gradient accumulation Ï≤¥ÌÅ¨
            if accumulated_batches >= config.gradient_accumulation_steps:
                # Gradient clipping and optimization step
                if config.use_mixed_precision:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)
                    optimizer.step()
                
                optimizer.zero_grad()
                accumulated_batches = 0
            
            # Metrics Í≥ÑÏÇ∞ (GPUÏóêÏÑú ÏßÅÏ†ë)
            with torch.no_grad():
                pred_masks_detached = pred_masks.detach()
                mask_detached = mask.detach()
                
                pred_masks_detached, mask_detached = safe_tensor_operations(
                    pred_masks_detached, mask_detached
                )
                
                dice = calculate_dice_safe(pred_masks_detached, mask_detached)
                iou = calculate_iou_safe(pred_masks_detached, mask_detached)
            
            # ÎàÑÏ†Å
            total_loss += losses['total_loss'].item()
            total_dice += dice
            total_iou += iou
            processed_batches += 1
            
            # Loss Ïª¥Ìè¨ÎÑåÌä∏ ÎàÑÏ†Å
            for key in loss_components:
                if key in losses:
                    loss_components[key] += losses[key].item()
            
            # Progress bar ÏóÖÎç∞Ïù¥Ìä∏
            current_lr = optimizer.param_groups[0]['lr']
            pbar.set_postfix({
                'Loss': f'{total_loss / processed_batches:.3f}',
                'Dice': f'{total_dice / processed_batches:.3f}',
                'IoU': f'{total_iou / processed_batches:.3f}',
                'LR': f'{current_lr:.2e}',
                'Mem': f'{torch.cuda.memory_allocated() / 1e9:.1f}GB' if torch.cuda.is_available() else 'N/A'
            })
            
            # Ï£ºÍ∏∞Ï†Å Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
            if batch_idx % 50 == 0:
                cleanup_memory()
            
            # ÌîÑÎ¶∞Ìä∏ Ï£ºÍ∏∞
            if processed_batches % config.print_freq == 0:
                elapsed = time.time() - start_time
                print(f"\n  Î∞∞Ïπò {processed_batches}/{len(dataloader)} - "
                      f"Loss: {total_loss / processed_batches:.4f}, "
                      f"ÏãúÍ∞Ñ: {elapsed:.1f}s")
                
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"\n‚ùå GPU Î©îÎ™®Î¶¨ Î∂ÄÏ°± (Î∞∞Ïπò {batch_idx}): {e}")
                print(f"üí° ÌòÑÏû¨ Î∞∞Ïπò ÌÅ¨Í∏∞: {image.shape[0]}, Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞: {image.shape}")
                cleanup_memory()
                
                # Î©îÎ™®Î¶¨ Î∂ÄÏ°±Ïãú Ìï¥Îãπ Î∞∞Ïπò Ïä§ÌÇµ
                if 'image' in locals():
                    del image
                if 'mask' in locals():
                    del mask
                if 'results' in locals():
                    del results
                continue
            else:
                print(f"‚ùå Î∞∞Ïπò {batch_idx} Ï≤òÎ¶¨ Ïã§Ìå®: {e}")
                continue
        except Exception as e:
            print(f"‚ùå Î∞∞Ïπò {batch_idx} Ï≤òÎ¶¨ Ïã§Ìå®: {e}")
            continue
    
    # ÎÇ®ÏùÄ gradientÍ∞Ä ÏûàÎã§Î©¥ ÏóÖÎç∞Ïù¥Ìä∏
    if accumulated_batches > 0:
        if config.use_mixed_precision:
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)
            scaler.step(optimizer)
            scaler.update()
        else:
            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)
            optimizer.step()
        optimizer.zero_grad()
    
    if processed_batches == 0:
        print("‚ö†Ô∏è Ï≤òÎ¶¨Îêú Î∞∞ÏπòÍ∞Ä ÏóÜÏäµÎãàÎã§!")
        return 0.0, 0.0, 0.0, {}
    
    # ÌèâÍ∑† Í≥ÑÏÇ∞
    avg_loss = total_loss / processed_batches
    avg_dice = total_dice / processed_batches
    avg_iou = total_iou / processed_batches
    
    # Loss Ïª¥Ìè¨ÎÑåÌä∏ ÌèâÍ∑†
    avg_loss_components = {
        key: value / processed_batches 
        for key, value in loss_components.items()
    }
    
    return avg_loss, avg_dice, avg_iou, avg_loss_components


def validate_epoch_improved(model, dataloader, device, config, epoch):
    """Í∞úÏÑ†Îêú Í≤ÄÏ¶ù ÏóêÌè¨ÌÅ¨ - Î©îÎ™®Î¶¨ Ìö®Ïú®Ï†Å Ï≤òÎ¶¨"""
    model.eval()
    
    total_loss = 0
    total_dice = 0
    total_iou = 0
    processed_batches = 0
    
    # Loss Ïª¥Ìè¨ÎÑåÌä∏Î≥Ñ Ï∂îÏ†Å
    loss_components = {
        'dice_loss': 0,
        'focal_loss': 0,
        'iou_loss': 0,
        'iou_pred_loss': 0,
        'representation_loss': 0
    }
    
    with torch.no_grad():
        pbar = tqdm(dataloader, desc=f"Validation Epoch {epoch+1}")
        start_time = time.time()
        
        for batch_idx, batch in enumerate(pbar):
            if batch is None or batch["patient_id"][0] == "dummy":
                continue
                
            try:
                image = batch["image"].to(device, non_blocking=True)
                mask = batch["mask"].to(device, non_blocking=True)
                
                # ÌÖêÏÑú Ïó∞ÏÜçÏÑ± Î≥¥Ïû•
                image = image.contiguous()
                mask = mask.contiguous()
                
                if image.shape[0] == 0 or mask.shape[0] == 0:
                    continue
                
                # Mixed precision forward pass
                with autocast(enabled=config.use_mixed_precision):
                    # Forward pass
                    results = model(image, mask)
                    pred_masks = results['pred_masks']
                    
                    if not pred_masks.is_contiguous():
                        pred_masks = pred_masks.contiguous()
                    
                    # Loss Í≥ÑÏÇ∞
                    loss_weights = {
                        'dice': config.dice_weight,
                        'focal': config.focal_weight,
                        'iou': config.iou_weight,
                        'iou_pred': config.iou_pred_weight,
                        'representation': config.repr_weight
                    }
                    
                    losses = model.calculate_loss(
                        pred_masks,
                        mask,
                        results.get('iou_predictions'),
                        results.get('representation_features'),
                        loss_weights=loss_weights
                    )
                
                # Metrics Í≥ÑÏÇ∞
                pred_masks, mask = safe_tensor_operations(pred_masks, mask)
                dice = calculate_dice_safe(pred_masks, mask)
                iou = calculate_iou_safe(pred_masks, mask)
                
                # ÎàÑÏ†Å
                total_loss += losses['total_loss'].item()
                total_dice += dice
                total_iou += iou
                processed_batches += 1
                
                # Loss Ïª¥Ìè¨ÎÑåÌä∏ ÎàÑÏ†Å
                for key in loss_components:
                    if key in losses:
                        loss_components[key] += losses[key].item()
                
                # Progress bar ÏóÖÎç∞Ïù¥Ìä∏
                pbar.set_postfix({
                    'Loss': f'{total_loss / processed_batches:.3f}',
                    'Dice': f'{total_dice / processed_batches:.3f}',
                    'IoU': f'{total_iou / processed_batches:.3f}',
                    'Mem': f'{torch.cuda.memory_allocated() / 1e9:.1f}GB' if torch.cuda.is_available() else 'N/A'
                })
                
                # Ï£ºÍ∏∞Ï†Å Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
                if batch_idx % 20 == 0:
                    cleanup_memory()
                
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"\n‚ùå Í≤ÄÏ¶ù Ï§ë GPU Î©îÎ™®Î¶¨ Î∂ÄÏ°± (Î∞∞Ïπò {batch_idx}): {e}")
                    cleanup_memory()
                    continue
                else:
                    print(f"‚ùå Í≤ÄÏ¶ù Î∞∞Ïπò {batch_idx} Ïã§Ìå®: {e}")
                    continue
            except Exception as e:
                print(f"‚ùå Í≤ÄÏ¶ù Î∞∞Ïπò {batch_idx} Ïã§Ìå®: {e}")
                continue
    
    if processed_batches == 0:
        print("‚ö†Ô∏è Í≤ÄÏ¶ùÏóêÏÑú Ï≤òÎ¶¨Îêú Î∞∞ÏπòÍ∞Ä ÏóÜÏäµÎãàÎã§!")
        return 0.0, 0.0, 0.0, {}
    
    # ÌèâÍ∑† Í≥ÑÏÇ∞
    avg_loss = total_loss / processed_batches
    avg_dice = total_dice / processed_batches
    avg_iou = total_iou / processed_batches
    
    # Loss Ïª¥Ìè¨ÎÑåÌä∏ ÌèâÍ∑†
    avg_loss_components = {
        key: value / processed_batches 
        for key, value in loss_components.items()
    }
    
    return avg_loss, avg_dice, avg_iou, avg_loss_components


def save_checkpoint_improved(model, optimizer, scheduler, scaler, epoch, metrics, config, 
                            checkpoint_type="regular"):
    """Í∞úÏÑ†Îêú Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•"""
    try:
        checkpoint_data = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
            'scaler_state_dict': scaler.state_dict() if scaler else None,
            'metrics': metrics,
            'config_dict': config.to_dict(),
            'checkpoint_type': checkpoint_type,
            'pytorch_version': torch.__version__
        }
        
        # ÌååÏùºÎ™Ö ÏÑ§Ï†ï
        if checkpoint_type == "best":
            filename = "best_model.pth"
        elif checkpoint_type == "latest":
            filename = "latest_model.pth"
        elif checkpoint_type == "sam_encoder":
            filename = "sam_encoder.pth"
        else:
            filename = f"checkpoint_epoch_{epoch:03d}.pth"
        
        filepath = os.path.join(config.output_dir, filename)
        
        # ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
        os.makedirs(config.output_dir, exist_ok=True)
        
        # Ï†ÄÏû•
        torch.save(checkpoint_data, filepath)
        
        # SAM encoderÎßå Î≥ÑÎèÑ Ï†ÄÏû• (BLIP2 Ìò∏Ìôò)
        if checkpoint_type == "best":
            try:
                sam_encoder_state = {
                    'image_encoder_state_dict': model.sam.image_encoder.state_dict(),
                    'metrics': metrics,
                    'config_dict': config.to_dict(),
                    'epoch': epoch
                }
                sam_encoder_path = os.path.join(config.output_dir, 'sam_encoder.pth')
                torch.save(sam_encoder_state, sam_encoder_path)
                print(f"üíæ SAM encoder Ï†ÄÏû•: {sam_encoder_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è SAM encoder Ï†ÄÏû• Ïã§Ìå®: {e}")
        
        print(f"üíæ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•: {filepath}")
        return filepath
        
    except Exception as e:
        print(f"‚ùå Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Ïã§Ìå®: {e}")
        return None


def load_checkpoint_improved(checkpoint_path, model, optimizer=None, scheduler=None, 
                           scaler=None, device='cuda'):
    """Í∞úÏÑ†Îêú Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎìú"""
    try:
        print(f"üìÇ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎìú Ï§ë: {checkpoint_path}")
        
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        # Î™®Îç∏ ÏÉÅÌÉú Î°úÎìú
        model.load_state_dict(checkpoint['model_state_dict'])
        
        # ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÉÅÌÉú Î°úÎìú
        if optimizer is not None and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        # Ïä§ÏºÄÏ§ÑÎü¨ ÏÉÅÌÉú Î°úÎìú
        if scheduler is not None and 'scheduler_state_dict' in checkpoint:
            if checkpoint['scheduler_state_dict'] is not None:
                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        # Scaler ÏÉÅÌÉú Î°úÎìú
        if scaler is not None and 'scaler_state_dict' in checkpoint:
            if checkpoint['scaler_state_dict'] is not None:
                scaler.load_state_dict(checkpoint['scaler_state_dict'])
        
        # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î∞òÌôò
        metadata = {
            'epoch': checkpoint.get('epoch', 0),
            'metrics': checkpoint.get('metrics', {}),
            'config': checkpoint.get('config_dict', {})
        }
        
        print(f"‚úÖ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎìú ÏôÑÎ£å (Epoch: {metadata['epoch']})")
        
        return metadata
        
    except Exception as e:
        print(f"‚ùå Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎìú Ïã§Ìå®: {e}")
        return None